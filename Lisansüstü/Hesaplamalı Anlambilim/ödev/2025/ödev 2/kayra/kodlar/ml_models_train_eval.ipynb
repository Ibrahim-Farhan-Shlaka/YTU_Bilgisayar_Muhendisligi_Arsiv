{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giriş işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers torch numpy pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kök dizin belirleme\n",
    "if is_colab():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    kok_dizin = \"/content/drive/MyDrive/TurkNLP-ModelBench\"\n",
    "else:\n",
    "    kok_dizin = os.getcwd()\n",
    "print(f\"Kök dizin: {kok_dizin}\\n Not: eğer colab kullanıyorsanız, dizini değiştirmeniz gerekir.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(kok_dizin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dizin_yardimcisi import (gomme_sonucu_ekle, hesaplanan_gomme_sayisi_al, gomme_bilgisi_oku, veri_kumesi_yukle,\n",
    "                               veri_kumesi_dizin_al, veri_kumesi_adlari_listele, gomme_basarimi_var_mi, gomme_basarimi_kaydet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri Kümeleri Okuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümeleri dizini alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_kumeleri_dizini = veri_kumesi_dizin_al()\n",
    "print(f\"Veri kümeleri dizini: {veri_kumeleri_dizini}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümesi adlarını alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_kumesi_adlari = veri_kumesi_adlari_listele(veri_kumeleri_dizini)\n",
    "print(f\"Veri kümeleri adları: {veri_kumesi_adlari}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümelerini oku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinama_kumeleri = {}\n",
    "egiti_kumeleri = {}\n",
    "print(\"Tüm veri kümeleri yükleniyor...\")\n",
    "for veri_kumesi_adi in veri_kumesi_adlari:\n",
    "    sinama_kumeleri[veri_kumesi_adi] = veri_kumesi_yukle(veri_kumesi_adi, egitim_kumesi_mi=False, klasor_yolu=veri_kumeleri_dizini)\n",
    "    print(f\"{veri_kumesi_adi}: {sinama_kumeleri[veri_kumesi_adi]}\")\n",
    "    egiti_kumeleri[veri_kumesi_adi] = veri_kumesi_yukle(veri_kumesi_adi, egitim_kumesi_mi=True, klasor_yolu=veri_kumeleri_dizini)\n",
    "    print(f\"{veri_kumesi_adi}: {egiti_kumeleri[veri_kumesi_adi]}\")\n",
    "veri_kumeleri = {\"sinama_kumeleri\": sinama_kumeleri, \"egiti_kumeleri\": egiti_kumeleri}\n",
    "print(\"Tüm veri kümeleri yüklendi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gömme İşlemleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gömme hesaplama fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_embedding(model: AutoModel, tokenizer: AutoTokenizer, text: str, device_type: str = \"cuda\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Verilen model ve tokenizer kullanarak bir metnin tek boyutlu cümle gömme vektörünü hesaplar.\n",
    "    Token seviyesindeki gömmelerden ortalama alarak tek bir vektör oluşturur.\n",
    "    \n",
    "    Args:\n",
    "        model: Hugging Face transformers kütüphanesinden bir AutoModel nesnesi\n",
    "        tokenizer: Model ile uyumlu bir AutoTokenizer nesnesi\n",
    "        text: Gömme vektörü oluşturulacak metin\n",
    "        device_type: Hesaplamanın yapılacağı cihaz tipi (\"cuda\" veya \"cpu\")\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Cümle gömme vektörünü içeren tek boyutlu numpy dizisi\n",
    "    \"\"\"\n",
    "    # Girdi metnini tokenize et\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Girdileri model ile aynı cihaza taşı\n",
    "    inputs = {k: v.to(device_type) for k, v in inputs.items()}\n",
    "    \n",
    "    # Model çıktılarını al - bellek tasarrufu için no_grad kullan\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Gömmeleri (son gizli durumları) al\n",
    "    # Boyut: [batch_size, sequence_length, hidden_size]\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    # Token gömmelerinin ortalamasını alarak cümle gömmesi oluştur\n",
    "    # (1, sequence_length, hidden_size) -> (hidden_size,)\n",
    "    sentence_embedding = embeddings.squeeze(0).mean(axis=0)\n",
    "    \n",
    "    # Numpy dizisine dönüştür ve döndür\n",
    "    return sentence_embedding.cpu().numpy()\n",
    "def get_row_embeddings(veri_satiri: pd.Series, model: AutoModel, tokenizer: AutoTokenizer, device_type: str=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Verilen veri satırı için hem sentence hem de label gömmelerini hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        veri_satiri: Bir veri satırı\n",
    "        model: Hugging Face transformers kütüphanesinden bir nesne\n",
    "        tokenizer: Model ile uyumlu bir nesne\n",
    "        device_type: Hesaplamanın yapılacağı cihaz tipi (\"cuda\" veya \"cpu\")\n",
    "    \n",
    "    Returns:\n",
    "        dict: \"sentence\" ve \"label\" anahtarları altında hesaplanan gömme vektörlerini içeren sözlük\n",
    "    \"\"\"\n",
    "    # Sentence gömmesini hesapla\n",
    "    sentence_embedding = get_token_embedding(model, tokenizer, veri_satiri['sentence'], device_type)\n",
    "    \n",
    "    # Label gömmesini hesapla (label bir sayı ise string'e çevir)\n",
    "    label_text = str(veri_satiri['label'])\n",
    "    label_embedding = get_token_embedding(model, tokenizer, label_text, device_type)\n",
    "    \n",
    "    # Gömmeleri sözlük olarak döndür\n",
    "    return {\n",
    "        \"sentence\": sentence_embedding,\n",
    "        \"label\": label_embedding\n",
    "    }\n",
    "\n",
    "def calculate_and_save_model_embeddings_specific_dataset(\n",
    "    model_name: str,\n",
    "    model: AutoModel, \n",
    "    tokenizer: AutoTokenizer, \n",
    "    veri_kumesi_adi: str,\n",
    "    df: pd.DataFrame,\n",
    "    model_dosya_adi_on_eki: str,\n",
    "    veri_kumesi_adi_on_eki: str,\n",
    "    device_type: str = \"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Belirtilen model ve veri kümesi için gömmeleri hesaplar ve kaydeder.\n",
    "    Varolan gömmeleri kontrol eder ve sadece hesaplanmayanları hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Model adı (string)\n",
    "        model: Hugging Face transformers kütüphanesinden bir AutoModel nesnesi\n",
    "        tokenizer: Model ile uyumlu bir AutoTokenizer nesnesi\n",
    "        veri_kumesi_adi: Veri kümesi adı (string)\n",
    "        df: İşlenecek pandas DataFrame\n",
    "        model_dosya_adi_on_eki: Model dosya adı ön eki\n",
    "        veri_kumesi_adi_on_eki: Veri kümesi adı ön eki\n",
    "        device_type: Hesaplamanın yapılacağı cihaz tipi (\"cuda\" veya \"cpu\")\n",
    "    \"\"\"\n",
    "    # Modeli belirtilen cihaza taşı\n",
    "    model.to(device_type)\n",
    "    \n",
    "    # Kaç gömmenin hesaplandığını kontrol et\n",
    "    hesaplanan_sayisi = hesaplanan_gomme_sayisi_al(model_dosya_adi_on_eki, veri_kumesi_adi_on_eki)\n",
    "    print(f\"{model_name}-{veri_kumesi_adi} model-veri kümesi için {hesaplanan_sayisi} adet gömme önceden hesaplanmış.\")\n",
    "    \n",
    "    # Tüm gömmeler zaten hesaplanmışsa, işlem yapma\n",
    "    if hesaplanan_sayisi >= len(df):\n",
    "        print(\"Tüm gömmeler zaten hesaplanmış.\")\n",
    "        return\n",
    "    \n",
    "    # Hesaplanacak gömmelerin aralığını belirle\n",
    "    baslangic_indeksi = hesaplanan_sayisi\n",
    "    toplam_ornek_sayisi = len(df)\n",
    "    \n",
    "    print(f\"Toplam {toplam_ornek_sayisi - baslangic_indeksi} adet gömme hesaplanacak.\")\n",
    "    \n",
    "    # Hesaplanmayan gömmeler için hesaplama yap\n",
    "    for idx in range(baslangic_indeksi, toplam_ornek_sayisi):\n",
    "        veri_satiri = df.iloc[idx]\n",
    "        \n",
    "        # Gömmeleri hesapla\n",
    "        embedding_result = get_row_embeddings(veri_satiri, model, tokenizer, device_type)\n",
    "        \n",
    "        # Ek bilgileri ekle\n",
    "        raw_embedding_dict = {\n",
    "            \"index\": idx,\n",
    "            \"model_name\": model_name,\n",
    "            \"dataset_name\": veri_kumesi_adi,\n",
    "            \"sentence\": veri_satiri['sentence'],\n",
    "            \"label\": int(veri_satiri['label']),\n",
    "            \"sentence_embedding\": embedding_result[\"sentence\"].tolist(),\n",
    "        }\n",
    "        \n",
    "        # Gömme sonucunu kaydet\n",
    "        gomme_sonucu_ekle(raw_embedding_dict, model_dosya_adi_on_eki, veri_kumesi_adi_on_eki)\n",
    "        \n",
    "        # Her 10 örnekte bir ilerleme raporu ver\n",
    "def get_token_embedding(model: AutoModel, tokenizer: AutoTokenizer, text: str, device_type: str = \"cuda\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Verilen model ve tokenizer kullanarak bir metnin tek boyutlu cümle gömme vektörünü hesaplar.\n",
    "    Token seviyesindeki gömmelerden ortalama alarak tek bir vektör oluşturur.\n",
    "    \n",
    "    Args:\n",
    "        model: Hugging Face transformers kütüphanesinden bir AutoModel nesnesi\n",
    "        tokenizer: Model ile uyumlu bir AutoTokenizer nesnesi\n",
    "        text: Gömme vektörü oluşturulacak metin\n",
    "        device_type: Hesaplamanın yapılacağı cihaz tipi (\"cuda\" veya \"cpu\")\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Cümle gömme vektörünü içeren tek boyutlu numpy dizisi\n",
    "    \"\"\"\n",
    "    # Girdi metnini tokenize et\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Girdileri model ile aynı cihaza taşı\n",
    "    inputs = {k: v.to(device_type) for k, v in inputs.items()}\n",
    "    \n",
    "    # Model çıktılarını al - bellek tasarrufu için no_grad kullan\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Gömmeleri (son gizli durumları) al\n",
    "    # Boyut: [batch_size, sequence_length, hidden_size]\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    # Token gömmelerinin ortalamasını alarak cümle gömmesi oluştur\n",
    "    # (1, sequence_length, hidden_size) -> (hidden_size,)\n",
    "    sentence_embedding = embeddings.squeeze(0).mean(axis=0)\n",
    "    \n",
    "    # Numpy dizisine dönüştür ve döndür\n",
    "    return sentence_embedding.cpu().numpy()\n",
    "def get_row_embeddings(veri_satiri: pd.Series, model: AutoModel, tokenizer: AutoTokenizer, device_type: str=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Verilen veri satırı için hem sentence hem de label gömmelerini hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        veri_satiri: Bir veri satırı\n",
    "        model: Hugging Face transformers kütüphanesinden bir nesne\n",
    "        tokenizer: Model ile uyumlu bir nesne\n",
    "        device_type: Hesaplamanın yapılacağı cihaz tipi (\"cuda\" veya \"cpu\")\n",
    "    \n",
    "    Returns:\n",
    "        dict: \"sentence\" ve \"label\" anahtarları altında hesaplanan gömme vektörlerini içeren sözlük\n",
    "    \"\"\"\n",
    "    # Sentence gömmesini hesapla\n",
    "    sentence_embedding = get_token_embedding(model, tokenizer, veri_satiri['sentence'], device_type)\n",
    "    \n",
    "    # Label gömmesini hesapla (label bir sayı ise string'e çevir)\n",
    "    label_text = str(veri_satiri['label'])\n",
    "    label_embedding = get_token_embedding(model, tokenizer, label_text, device_type)\n",
    "    \n",
    "    # Gömmeleri sözlük olarak döndür\n",
    "    return {\n",
    "        \"sentence\": sentence_embedding,\n",
    "        \"label\": label_embedding\n",
    "    }\n",
    "\n",
    "def calculate_and_save_model_embeddings_specific_dataset(\n",
    "    model_name: str,\n",
    "    model: AutoModel, \n",
    "    tokenizer: AutoTokenizer, \n",
    "    veri_kumesi_adi: str,\n",
    "    df: pd.DataFrame,\n",
    "    model_dosya_adi_on_eki: str,\n",
    "    veri_kumesi_adi_on_eki: str,\n",
    "    device_type: str = \"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Belirtilen model ve veri kümesi için gömmeleri hesaplar ve kaydeder.\n",
    "    Varolan gömmeleri kontrol eder ve sadece hesaplanmayanları hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Model adı (string)\n",
    "        model: Hugging Face transformers kütüphanesinden bir AutoModel nesnesi\n",
    "        tokenizer: Model ile uyumlu bir AutoTokenizer nesnesi\n",
    "        veri_kumesi_adi: Veri kümesi adı (string)\n",
    "        df: İşlenecek pandas DataFrame\n",
    "        model_dosya_adi_on_eki: Model dosya adı ön eki\n",
    "        veri_kumesi_adi_on_eki: Veri kümesi adı ön eki\n",
    "        device_type: Hesaplamanın yapılacağı cihaz tipi (\"cuda\" veya \"cpu\")\n",
    "    \"\"\"\n",
    "    # Modeli belirtilen cihaza taşı\n",
    "    model.to(device_type)\n",
    "    \n",
    "    # Kaç gömmenin hesaplandığını kontrol et\n",
    "    hesaplanan_sayisi = hesaplanan_gomme_sayisi_al(model_dosya_adi_on_eki, veri_kumesi_adi_on_eki)\n",
    "    print(f\"{model_name}-{veri_kumesi_adi} model-veri kümesi için {hesaplanan_sayisi} adet gömme önceden hesaplanmış.\")\n",
    "    \n",
    "    # Tüm gömmeler zaten hesaplanmışsa, işlem yapma\n",
    "    if hesaplanan_sayisi >= len(df):\n",
    "        print(\"Tüm gömmeler zaten hesaplanmış.\")\n",
    "        return\n",
    "    \n",
    "    # Hesaplanacak gömmelerin aralığını belirle\n",
    "    baslangic_indeksi = hesaplanan_sayisi\n",
    "    toplam_ornek_sayisi = len(df)\n",
    "    \n",
    "    print(f\"Toplam {toplam_ornek_sayisi - baslangic_indeksi} adet gömme hesaplanacak.\")\n",
    "    \n",
    "    # Hesaplanmayan gömmeler için hesaplama yap\n",
    "    for idx in range(baslangic_indeksi, toplam_ornek_sayisi):\n",
    "        veri_satiri = df.iloc[idx]\n",
    "        \n",
    "        # Gömmeleri hesapla\n",
    "        embedding_result = get_row_embeddings(veri_satiri, model, tokenizer, device_type)\n",
    "        \n",
    "        # Ek bilgileri ekle\n",
    "        raw_embedding_dict = {\n",
    "            \"index\": idx,\n",
    "            \"model_name\": model_name,\n",
    "            \"dataset_name\": veri_kumesi_adi,\n",
    "            \"sentence\": veri_satiri['sentence'],\n",
    "            \"label\": int(veri_satiri['label']),\n",
    "            \"sentence_embedding\": embedding_result[\"sentence\"].tolist(),\n",
    "        }\n",
    "        \n",
    "        # Gömme sonucunu kaydet\n",
    "        gomme_sonucu_ekle(raw_embedding_dict, model_dosya_adi_on_eki, veri_kumesi_adi_on_eki)\n",
    "        \n",
    "        # Her 10 örnekte bir ilerleme raporu ver\n",
    "        if (idx - baslangic_indeksi + 1) % 10 == 0 or idx == toplam_ornek_sayisi - 1:\n",
    "            print(f\"İlerleme: {idx - baslangic_indeksi + 1}/{toplam_ornek_sayisi - baslangic_indeksi} ({((idx - baslangic_indeksi + 1) / (toplam_ornek_sayisi - baslangic_indeksi)) * 100:.2f}%)\", end=\"\\r\")\n",
    "    \n",
    "    print(f\"Tüm gömmeler başarıyla hesaplandı ve kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_dosya_adi_on_eki(model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Model dosya adı ön ekini döndürür.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Model adı (string)\n",
    "    \n",
    "    Returns:\n",
    "        str: Model dosya adı ön eki\n",
    "    \"\"\"\n",
    "    return model_name.lower().replace(\"/\", \"_\")\n",
    "def get_veri_kumesi_adi_on_eki(veri_kumesi_tipi: str, veri_kumesi_adi: str) -> str:\n",
    "    \"\"\"\n",
    "    Veri kümesi adı ön ekini döndürür.\n",
    "    \n",
    "    Args:\n",
    "        veri_kumesi_tipi: Veri kümesi tipi (egitim veya sinama)\n",
    "        veri_kumesi_adi: Veri kümesi adı\n",
    "    \n",
    "    Returns:\n",
    "        str: Veri kümesi adı ön eki\n",
    "    \"\"\"\n",
    "    return veri_kumesi_tipi + \"_\" + veri_kumesi_adi.lower().replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gömmeleri hesapla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Kullanılan cihaz tipi: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"intfloat/multilingual-e5-base\",                                # 278M  - 33\n",
    "    \"ibm-granite/granite-embedding-107m-multilingual\",              # 107M  - 48\n",
    "    \"intfloat/multilingual-e5-small\",                               # 118M  - 36\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",  # 118M  - 62\n",
    "    \"shibing624/text2vec-base-multilingual\",                        # 118M  - 77 \n",
    "    ]\n",
    "for i, model_name in enumerate(model_names):\n",
    "    print(f\"Model: {model_name} yükleniyor...\")\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    for veri_kumesi_tipi in veri_kumeleri.keys():\n",
    "        for veri_kumesi_adi in veri_kumeleri[veri_kumesi_tipi].keys():\n",
    "            islenecek_veri_kumesi = veri_kumeleri[veri_kumesi_tipi][veri_kumesi_adi]\n",
    "            veri_kumesi_adi_on_eki = get_veri_kumesi_adi_on_eki(veri_kumesi_tipi, veri_kumesi_adi)\n",
    "            calculate_and_save_model_embeddings_specific_dataset(\n",
    "                model_name,\n",
    "                model,\n",
    "                tokenizer,\n",
    "                veri_kumesi_adi,\n",
    "                islenecek_veri_kumesi,\n",
    "                get_model_dosya_adi_on_eki(model_name),\n",
    "                veri_kumesi_adi_on_eki,\n",
    "                device_type=device\n",
    "            )\n",
    "    print(f\"Model: {model_name} yüklendi ve gömme hesaplamaları tamamlandı. ({i + 1}/{len(model_names)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gömmeleri yükle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıdaki yapıda yüklenir. Eğitim ve sınama kümeleri altında farklı veri kümeleri vardır. onun da altında her veri kümesi için farklı gömme modelleriyle elde edilen gömme sonuçları bulunmaktadır.\n",
    "```json\n",
    "{\n",
    "    \"veri_kumesi_tipi\": \"sinama_kumeleri\",\n",
    "    \"gommeler\": [\n",
    "        {\n",
    "            \"veri_kumesi_adi\": \"sst2\",\n",
    "            \"intfloat/multilingual-e5-base\": [],\n",
    "            \"ibm-granite/granite-embedding-107m-multilingual\": [],\n",
    "            \"intfloat/multilingual-e5-small\": [],\n",
    "            \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\": [],\n",
    "            \"shibing624/text2vec-base-multilingual\": []\n",
    "        },\n",
    "        {\n",
    "            \"veri_kumesi_adi\": \"cola\",\n",
    "            \"intfloat/multilingual-e5-base\": [],\n",
    "            \"ibm-granite/granite-embedding-107m-multilingual\": [],\n",
    "            \"intfloat/multilingual-e5-small\": [],\n",
    "            \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\": [],\n",
    "            \"shibing624/text2vec-base-multilingual\": []\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "{\n",
    "    \"veri_kumesi_tipi\": \"egiti_kumeleri\",\n",
    "    \"gommeler\": [\n",
    "        {\n",
    "            \"veri_kumesi_adi\": \"sst2\",\n",
    "            \"intfloat/multilingual-e5-base\": [],\n",
    "            \"ibm-granite/granite-embedding-107m-multilingual\": [],\n",
    "            \"intfloat/multilingual-e5-small\": [],\n",
    "            \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\": [],\n",
    "            \"shibing624/text2vec-base-multilingual\": []\n",
    "        },\n",
    "        {\n",
    "            \"veri_kumesi_adi\": \"cola\",\n",
    "            \"intfloat/multilingual-e5-base\": [],\n",
    "            \"ibm-granite/granite-embedding-107m-multilingual\": [],\n",
    "            \"intfloat/multilingual-e5-small\": [],\n",
    "            \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\": [],\n",
    "            \"shibing624/text2vec-base-multilingual\": []\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_kumeleri_gommeleri = []\n",
    "# sırayla önce sınama sonra eğitim kümesi için gömme yükle\n",
    "for veri_kumesi_tipi in veri_kumeleri.keys():\n",
    "    tip_gommeleri = {}\n",
    "    tip_gommeleri[\"veri_kumesi_tipi\"] = veri_kumesi_tipi\n",
    "    tip_gommeleri[\"gommeler\"] = []\n",
    "    # eğitim/sınama\n",
    "    tipe_gore_veri_kumeleri = veri_kumeleri[veri_kumesi_tipi]\n",
    "    # sst2 ve cola'la gez\n",
    "    for veri_kumesi_adi in tipe_gore_veri_kumeleri.keys():\n",
    "        # sst2/cola'nın tüm modellerdeki gömmeleri\n",
    "        veri_kumesi_gommeleri = {}\n",
    "        veri_kumesi_gommeleri[\"veri_kumesi_adi\"] = veri_kumesi_adi\n",
    "        for i, model_name in enumerate(model_names):\n",
    "            veri_kumesi_adi_on_eki = get_veri_kumesi_adi_on_eki(veri_kumesi_tipi, veri_kumesi_adi)\n",
    "            model_dosya_adi_on_eki = get_model_dosya_adi_on_eki(model_name)\n",
    "            # model-veri kümesi için gömme yükle (tipe göre eğitim/sınama)\n",
    "            veri_kumesi_gommeleri[model_name] = gomme_bilgisi_oku(model_dosya_adi_on_eki, veri_kumesi_adi_on_eki)\n",
    "            print(f\"{model_name}-{veri_kumesi_adi} model-veri kümesi için {len(veri_kumesi_gommeleri[model_name])} adet gömme yüklendi. ({i + 1}/{len(model_names)})\")\n",
    "        tip_gommeleri[\"gommeler\"].append(veri_kumesi_gommeleri)\n",
    "    veri_kumeleri_gommeleri.append(tip_gommeleri)\n",
    "print(\"Tüm gömme verileri yüklendi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yüklenen gömmeleri modeli veri kümesi adı ve tipine göre getirme fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gomme_getir(veri_kumeleri_gommeleri: list, veri_kumesi_adi: str, model_name: str, veri_kumesi_tipi: str) -> list:\n",
    "    \"\"\"\n",
    "    Verilen veri kümesi adı, model adı ve veri kümesi tipine göre gömme vektörlerini döndürür.\n",
    "\n",
    "    Args:\n",
    "        veri_kumeleri_gommeleri: Gömme verileri\n",
    "        veri_kumesi_adi: Veri kümesi adı\n",
    "        model_name: Model adı\n",
    "        veri_kumesi_tipi: Veri kümesi tipi\n",
    "    Returns:\n",
    "        list: Gömme vektörlerini içeren liste\n",
    "    \"\"\"\n",
    "    if veri_kumeleri_gommeleri[0][\"veri_kumesi_tipi\"] == veri_kumesi_tipi:\n",
    "        tip_gommeleri = veri_kumeleri_gommeleri[0][\"gommeler\"]\n",
    "    else:\n",
    "        tip_gommeleri = veri_kumeleri_gommeleri[1][\"gommeler\"]\n",
    "    for veri_kumesi_gommeleri in tip_gommeleri:\n",
    "        if veri_kumesi_gommeleri[\"veri_kumesi_adi\"] == veri_kumesi_adi:\n",
    "            return veri_kumesi_gommeleri[model_name]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tipine göre eğitme, oluşturma ve sınama fonksiyonları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_getir(model_sinifi, seed=42):\n",
    "    \"\"\"\n",
    "    Gömme boyutuna ve model tipine göre model oluşturup döndürür.\n",
    "    \n",
    "    Parametreler:\n",
    "        model_sinifi: Kullanılacak model sınıfı (RandomForestClassifier, LogisticRegression, SVC vb.)\n",
    "        seed: Rastgelelik için kullanılacak tohum değeri\n",
    "        \n",
    "    Dönüş:\n",
    "        Oluşturulan model nesnesi\n",
    "    \"\"\"\n",
    "    if model_sinifi == RandomForestClassifier:\n",
    "        return RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "    elif model_sinifi == LogisticRegression:\n",
    "        return LogisticRegression(max_iter=1000, random_state=seed)\n",
    "    elif model_sinifi == SVC:\n",
    "        return SVC(probability=True, random_state=seed)\n",
    "    else:\n",
    "        raise ValueError(\"Desteklenmeyen model sınıfı\")\n",
    "\n",
    "def model_egit(model, egitim_gommeleri):\n",
    "    \"\"\"\n",
    "    Verilen modeli eğitim gömmelerini kullanarak eğitir.\n",
    "    \n",
    "    Parametreler:\n",
    "        model: Eğitilecek model nesnesi\n",
    "        egitim_gommeleri: Eğitim için kullanılacak gömme vektörleri listesi\n",
    "        \n",
    "    Dönüş:\n",
    "        Eğitilmiş model nesnesi\n",
    "    \"\"\"\n",
    "    # Eğitim verilerinden X (özellikler) ve y (etiketler) oluşturma\n",
    "    X_train = np.vstack([gomme[\"sentence_embedding\"] for gomme in egitim_gommeleri])\n",
    "    y_train = np.array([gomme[\"label\"] for gomme in egitim_gommeleri])\n",
    "    \n",
    "    # Modeli eğit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def model_basari_hesapla(model, sinama_gommeleri):\n",
    "    \"\"\"\n",
    "    Eğitilmiş modelin sınama gömmelerindeki başarı metriklerini hesaplar.\n",
    "    \n",
    "    Parametreler:\n",
    "        model: Değerlendirilecek eğitilmiş model nesnesi\n",
    "        sinama_gommeleri: Test için kullanılacak gömme vektörleri listesi\n",
    "        \n",
    "    Dönüş:\n",
    "        dict: Accuracy, precision, recall, f1 ve diğer metrikleri içeren sözlük\n",
    "    \"\"\"\n",
    "    # Test verilerinden X (özellikler) ve y (etiketler) oluşturma\n",
    "    X_test = np.vstack([gomme[\"sentence_embedding\"] for gomme in sinama_gommeleri])\n",
    "    y_test = np.array([gomme[\"label\"] for gomme in sinama_gommeleri])\n",
    "    \n",
    "    # Tahminler\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrikler\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Sonuçları sözlük olarak döndür\n",
    "    sonuc = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    }\n",
    "    \n",
    "    return sonuc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelleri eğit ve sına"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model_tipleri = [RandomForestClassifier, LogisticRegression, SVC]\n",
    "ml_model_tipleri_str = [\"Rastgele Orman (Random Forest)\", \"Lojistik Regresyon (Logistic Regression)\", \"Destek Vektör Makineleri (Support Vector Machines)\"]\n",
    "for veri_kumesi_adi in veri_kumesi_adlari:\n",
    "    for model_name in model_names:\n",
    "        for i in range(len(ml_model_tipleri)):\n",
    "            if not gomme_basarimi_var_mi(ml_model_tipleri_str[i], model_name, veri_kumesi_adi):\n",
    "                egitim_gommeleri = gomme_getir(veri_kumeleri_gommeleri, veri_kumesi_adi, model_name, \"egitim_kumeleri\")\n",
    "                sinama_gommeleri = gomme_getir(veri_kumeleri_gommeleri, veri_kumesi_adi, model_name, \"sinama_kumeleri\")\n",
    "                print(f\"{veri_kumesi_adi} veri kümesi için {model_name} modeli ve {ml_model_tipleri_str[i]} için doğruluk değeri hesaplanıyor...\", end=\"\\r\")\n",
    "                model = model_getir(ml_model_tipleri[i])\n",
    "                model = model_egit(model, egitim_gommeleri)\n",
    "                basari_dict = model_basari_hesapla(model, sinama_gommeleri)\n",
    "                gomme_basarimi_kaydet(basari_dict, ml_model_tipleri_str[i], model_name, veri_kumesi_adi)\n",
    "                print(f\"{veri_kumesi_adi} veri kümesi için {model_name} modeli ve {ml_model_tipleri_str[i]} için doğruluk değeri hesaplandı. ({i + 1}/{len(ml_model_tipleri)})\", end=\"\\r\")\n",
    "            else:\n",
    "                print(f\"{veri_kumesi_adi} veri kümesi için {model_name} modeli ve {ml_model_tipleri_str[i]} için doğruluk değeri zaten hesaplanmış.\")\n",
    "        print(f\"\\n{veri_kumesi_adi} veri kümesi için {model_name} modeli için doğruluk değerleri hesaplandı. ({model_names.index(model_name) + 1}/{len(model_names)})\")\n",
    "    print(f\"{veri_kumesi_adi} veri kümesi için tüm model doğruluk değerleri hesaplandı.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Çizdirme işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cizdir import gomme_modeli_basari_puanlari_cizdir, gomme_modeli_f1_puanlari_cizdir, \\\n",
    "    gomme_modeli_recall_puanlari_cizdir, gomme_modeli_basari_puanlari_cizdir, gomme_modeli_conf_matris_cizdir\n",
    "from dizin_yardimcisi import gomme_basarimlari_oku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "renkler = ['#8B4513', '#8B0000', '#006400'] \n",
    "gomme_sonuclari = gomme_basarimlari_oku()\n",
    "for veri_kumesi_adi in veri_kumesi_adlari:\n",
    "    gomme_modeli_basari_puanlari_cizdir(f\"{veri_kumesi_adi} Sonuçları\", gomme_sonuclari[veri_kumesi_adi], veri_kumesi_adi)\n",
    "    gomme_modeli_f1_puanlari_cizdir(f\"{veri_kumesi_adi} Sonuçları\", gomme_sonuclari[veri_kumesi_adi], veri_kumesi_adi)\n",
    "    gomme_modeli_recall_puanlari_cizdir(f\"{veri_kumesi_adi} Sonuçları\", gomme_sonuclari[veri_kumesi_adi], veri_kumesi_adi)\n",
    "    gomme_modeli_basari_puanlari_cizdir(f\"{veri_kumesi_adi} Sonuçları\", gomme_sonuclari[veri_kumesi_adi], veri_kumesi_adi)\n",
    "    for ml_model_name in ml_model_tipleri_str:\n",
    "        for model_name in model_names:\n",
    "            gomme_modeli_conf_matris_cizdir(f\"{veri_kumesi_adi} Sonuçları\", gomme_sonuclari[veri_kumesi_adi], veri_kumesi_adi,\n",
    "                                             ml_model_name, model_name, get_model_dosya_adi_on_eki(model_name))\n",
    "    print(f\"{model_name}-{veri_kumesi_adi} model-veri kümesi için başarı puanları çizdirildi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
